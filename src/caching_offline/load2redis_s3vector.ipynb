{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b912f8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/27 03:25:54 WARNING mlflow.pytorch: Stored model version '2.6.0+cu124' does not match installed PyTorch version '2.4.1+cu121'\n",
      "/home/duong/anaconda3/envs/pipeline-caching/lib/python3.11/site-packages/torch/serialization.py:1074: UserWarning: 'torch.load' received a zip file that looks like a TorchScript archive dispatching to 'torch.jit.load' (call 'torch.jit.load' directly to silence this warning)\n",
      "  warnings.warn(\"'torch.load' received a zip file that looks like a TorchScript archive\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded model v1 (run_id=aac89aa42a3c447eac1294546df933e6) and IDMapper.\n",
      "\n",
      "ðŸ”¹ Embedding for 'B00000IV95' (index 36): [ 0.05149313  0.0443965  -0.01442701  0.07874709  0.07239346]\n",
      "\n",
      "ðŸ”¹ Top 5 similar items to 'B00000IV95':\n",
      " - B0C3H818H4 (index 4009): score = 2.2501\n",
      " - B0C48KPLZ2 (index 4026): score = 1.6529\n",
      " - 0975277324 (index 5): score = 1.6294\n",
      " - B0C1FX3BGK (index 3976): score = 1.5719\n",
      " - B00000IV35 (index 35): score = 1.5157\n",
      "\n",
      "ðŸ”¹ Batch prediction scores:\n",
      " - (B00000IV95, B0792X1RSC): score = 0.5309\n",
      " - (B0792X1RSC, B00000IV95): score = 0.5309\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import mlflow\n",
    "import torch\n",
    "import numpy as np\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.store.artifact.s3_artifact_repo import S3ArtifactRepository\n",
    "\n",
    "\n",
    "# === Cáº¥u hÃ¬nh MLflow + MinIO ===\n",
    "def configure_mlflow(\n",
    "    s3_endpoint: str, aws_key: str, aws_secret: str, tracking_uri: str\n",
    "):\n",
    "    os.environ.update(\n",
    "        {\n",
    "            \"AWS_ACCESS_KEY_ID\": aws_key,\n",
    "            \"AWS_SECRET_ACCESS_KEY\": aws_secret,\n",
    "            \"MLFLOW_S3_ENDPOINT_URL\": s3_endpoint,\n",
    "            \"MLFLOW_S3_IGNORE_TLS\": \"true\",\n",
    "        }\n",
    "    )\n",
    "    mlflow.set_tracking_uri(tracking_uri)\n",
    "\n",
    "    session = boto3.session.Session(\n",
    "        aws_access_key_id=aws_key, aws_secret_access_key=aws_secret\n",
    "    )\n",
    "    S3ArtifactRepository._get_s3_client = lambda self: session.client(\n",
    "        \"s3\", endpoint_url=s3_endpoint\n",
    "    )\n",
    "\n",
    "\n",
    "# === IDMapper Ä‘Æ¡n giáº£n ===\n",
    "class SimpleIDMapper:\n",
    "    def __init__(self, mapping_path: str):\n",
    "        with open(mapping_path, \"r\") as f:\n",
    "            mapping = json.load(f)\n",
    "        self.item_to_index: Dict[str, int] = mapping[\"item_to_index\"]\n",
    "        self.index_to_item: Dict[int, str] = mapping[\"index_to_item\"]\n",
    "\n",
    "\n",
    "# === Load TorchScript model + IDMapper tá»« registered model ===\n",
    "def load_champion_model(\n",
    "    model_name: str,\n",
    ") -> Tuple[torch.jit.ScriptModule, SimpleIDMapper]:\n",
    "    client = MlflowClient()\n",
    "    versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "    champs = [v for v in versions if v.tags.get(\"champion\", \"\").lower() == \"true\"]\n",
    "    if not champs:\n",
    "        raise RuntimeError(f\"No champion version found for model '{model_name}'\")\n",
    "\n",
    "    champ = max(champs, key=lambda v: v.creation_timestamp)\n",
    "    run_id = champ.run_id\n",
    "    model = mlflow.pytorch.load_model(f\"models:/{model_name}/{champ.version}\")\n",
    "    model.eval()\n",
    "\n",
    "    id_mapper_path = f\"runs:/{run_id}/id_mapper/id_mapper.json\"\n",
    "    id_mapper_local = mlflow.artifacts.download_artifacts(id_mapper_path)\n",
    "    id_mapper = SimpleIDMapper(id_mapper_local)\n",
    "\n",
    "    print(f\"Loaded model v{champ.version} (run_id={run_id}) and IDMapper.\")\n",
    "    return model, id_mapper\n",
    "\n",
    "\n",
    "# === Inference Utilities ===\n",
    "def get_item_embedding(\n",
    "    model, id_mapper, item_id, device=torch.device(\"cpu\")\n",
    ") -> torch.Tensor:\n",
    "    idx = torch.tensor([id_mapper.item_to_index[item_id]], device=device)\n",
    "    return model.embeddings(idx).squeeze(0)\n",
    "\n",
    "\n",
    "def get_topk_similar(\n",
    "    model, id_mapper, item_id, top_k=10, device=torch.device(\"cpu\")\n",
    ") -> List[Tuple[str, int, float]]:\n",
    "    target_idx = id_mapper.item_to_index[item_id]\n",
    "    weight = model.embeddings.weight[:-1].to(device)  # exclude padding_idx\n",
    "    with torch.no_grad():\n",
    "        target_emb = weight[target_idx]\n",
    "        sims = torch.matmul(weight, target_emb)\n",
    "    sims[target_idx] = -np.inf  # exclude self\n",
    "    topk = torch.topk(sims, k=top_k)\n",
    "    return [\n",
    "        (id_mapper.index_to_item[int(i)], int(i), float(s))\n",
    "        for i, s in zip(topk.indices, topk.values)\n",
    "    ]\n",
    "\n",
    "\n",
    "def predict_batch(\n",
    "    model, id_mapper, batch: Dict[str, List[str]], device=torch.device(\"cpu\")\n",
    ") -> np.ndarray:\n",
    "    tgt = torch.tensor(\n",
    "        [id_mapper.item_to_index[i] for i in batch[\"target_items\"]], device=device\n",
    "    )\n",
    "    ctx = torch.tensor(\n",
    "        [id_mapper.item_to_index[i] for i in batch[\"context_items\"]], device=device\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        return model(tgt, ctx).cpu().numpy()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    configure_mlflow(\n",
    "        s3_endpoint=\"http://127.0.0.1:9010\",\n",
    "        aws_key=\"admin\",\n",
    "        aws_secret=\"Password1234\",\n",
    "        tracking_uri=\"http://localhost:5002\",\n",
    "    )\n",
    "\n",
    "    model_name = \"item2vec_skipgram\"\n",
    "    model, id_mapper = load_champion_model(model_name)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    test_item = \"B00000IV95\"\n",
    "    test_idx = id_mapper.item_to_index[test_item]\n",
    "    emb = get_item_embedding(model, id_mapper, test_item, device)\n",
    "    print(\n",
    "        f\"\\nðŸ”¹ Embedding for '{test_item}' (index {test_idx}): {emb[:5].detach().cpu().numpy()}\"\n",
    "    )\n",
    "\n",
    "    topk = get_topk_similar(model, id_mapper, test_item, top_k=5, device=device)\n",
    "    print(f\"\\nðŸ”¹ Top 5 similar items to '{test_item}':\")\n",
    "    for iid, idx, score in topk:\n",
    "        print(f\" - {iid} (index {idx}): score = {score:.4f}\")\n",
    "\n",
    "    batch = {\n",
    "        \"target_items\": [test_item, \"B0792X1RSC\"],\n",
    "        \"context_items\": [\"B0792X1RSC\", test_item],\n",
    "    }\n",
    "    scores = predict_batch(model, id_mapper, batch, device)\n",
    "    print(f\"\\nðŸ”¹ Batch prediction scores:\")\n",
    "    for t, c, s in zip(batch[\"target_items\"], batch[\"context_items\"], scores):\n",
    "        print(f\" - ({t}, {c}): score = {s:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba55f881",
   "metadata": {},
   "source": [
    "# Load embedding to S3 vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fa9e4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/27 09:09:09 WARNING mlflow.pytorch: Stored model version '2.6.0+cu124' does not match installed PyTorch version '2.4.1+cu121'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting embedding indexing...\n",
      "Loading model from URI: models:/item2vec_skipgram/1\n",
      "Loaded model version 1 (run_id=aac89aa42a3c447eac1294546df933e6) with 4143 items.\n",
      "Extracted embeddings with shape (4143, 256)\n",
      "Checking index configuration...\n",
      "Index config: {\n",
      "  \"vectorBucketName\": \"recsys-ops-s3-vector\",\n",
      "  \"indexName\": \"item2vec-index-dim-256\",\n",
      "  \"indexArn\": \"arn:aws:s3vectors:us-east-1:796973475591:bucket/recsys-ops-s3-vector/index/item2vec-index-dim-256\",\n",
      "  \"creationTime\": \"2025-07-27 09:00:53+07:00\"\n",
      "}\n",
      "Indexing embeddings...\n",
      "Connecting to S3 Vectors in region us-east-1\n",
      "Deleted existing index 'item2vec-index-dim-256' to clear all old vectors.\n",
      "Created new index 'item2vec-index-dim-256' with dim=256\n",
      "Normalized embeddings, sample norm: 1.0000\n",
      "Sample vector metadata: {'item_id': '0439893577', 'category': 'item', 'index_timestamp': '2025-07-27'}\n",
      "Sample vector first 5 values: [-0.11034437268972397, 0.10069891065359116, -0.10829982906579971, 0.0698055773973465, -0.04339940473437309]\n",
      "Inserted batch 1 (500 vectors)\n",
      "Inserted batch 2 (500 vectors)\n",
      "Inserted batch 3 (500 vectors)\n",
      "Inserted batch 4 (500 vectors)\n",
      "Inserted batch 5 (500 vectors)\n",
      "Inserted batch 6 (500 vectors)\n",
      "Inserted batch 7 (500 vectors)\n",
      "Inserted batch 8 (500 vectors)\n",
      "Inserted batch 9 (143 vectors)\n",
      "Completed inserting 4143 embeddings into S3 Vectors index 'item2vec-index-dim-256' in bucket 'recsys-ops-s3-vector'\n",
      "Saved embeddings and item_ids for debugging.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import mlflow\n",
    "import torch\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.store.artifact.s3_artifact_repo import S3ArtifactRepository\n",
    "import boto3\n",
    "import warnings\n",
    "\n",
    "# Suppress PyTorch warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Configuration\n",
    "PROJECT_ROOT = os.getenv(\n",
    "    \"PROJECT_ROOT\", \"/home/duong/Documents/datn1/src/model_item2vec\"\n",
    ")\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# MLflow/MinIO config\n",
    "S3_ENDPOINT = os.getenv(\"MLFLOW_S3_ENDPOINT\", \"http://127.0.0.1:9010\")\n",
    "AWS_KEY_MINIO = os.getenv(\"AWS_ACCESS_KEY_ID_MINIO\", \"admin\")\n",
    "AWS_SECRET_MINIO = os.getenv(\"AWS_SECRET_ACCESS_KEY_MINIO\", \"Password1234\")\n",
    "TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\", \"http://localhost:5002\")\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = AWS_KEY_MINIO\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = AWS_SECRET_MINIO\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = S3_ENDPOINT\n",
    "os.environ[\"MLFLOW_S3_IGNORE_TLS\"] = \"true\"\n",
    "\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "\n",
    "# Configure boto3 for MinIO (for MLflow artifacts)\n",
    "minio_session = boto3.session.Session(\n",
    "    aws_access_key_id=AWS_KEY_MINIO, aws_secret_access_key=AWS_SECRET_MINIO\n",
    ")\n",
    "S3ArtifactRepository._get_s3_client = lambda self: minio_session.client(\n",
    "    \"s3\", endpoint_url=S3_ENDPOINT\n",
    ")\n",
    "\n",
    "# S3 Vectors config\n",
    "S3_VECTOR_BUCKET = os.getenv(\"S3_VECTOR_BUCKET\", \"recsys-ops-s3-vector\")\n",
    "S3_VECTOR_INDEX = os.getenv(\"S3_VECTOR_INDEX\", \"item2vec-index-dim-256\")\n",
    "AWS_REGION = \"us-east-1\"\n",
    "AWS_KEY_S3 = os.getenv(\"AWS_ACCESS_KEY_ID_AWS\", \"AKIA3TD2SE4D4EJQWMMS\")\n",
    "AWS_SECRET_S3 = os.getenv(\n",
    "    \"AWS_SECRET_ACCESS_KEY_AWS\", \"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\"\n",
    ")\n",
    "\n",
    "# Model config\n",
    "MODEL_NAME = os.getenv(\"MODEL_NAME\", \"item2vec_skipgram\")\n",
    "TAG_NAME = os.getenv(\"MODEL_TAG\", \"champion\")\n",
    "\n",
    "\n",
    "# SimpleIDMapper\n",
    "class SimpleIDMapper:\n",
    "    def __init__(self, mapping_path: str):\n",
    "        with open(mapping_path, \"r\") as f:\n",
    "            mapping = json.load(f)\n",
    "        self.item_to_index = mapping[\"item_to_index\"]\n",
    "        self.index_to_item = mapping[\"index_to_item\"]\n",
    "\n",
    "\n",
    "# Load model and ID mapping\n",
    "def load_model_from_mlflow(model_name: str, tag: str) -> tuple:\n",
    "    client = MlflowClient()\n",
    "    versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "    champs = [v for v in versions if v.tags.get(tag, \"\").lower() == \"true\"]\n",
    "    if not champs:\n",
    "        raise ValueError(f\"No version tagged '{tag}' found for model '{model_name}'.\")\n",
    "\n",
    "    champ = max(champs, key=lambda v: v.creation_timestamp)\n",
    "    run_id = champ.run_id\n",
    "    model_uri = f\"models:/{model_name}/{champ.version}\"\n",
    "    print(f\"Loading model from URI: {model_uri}\")\n",
    "    model = mlflow.pytorch.load_model(model_uri)\n",
    "    model.eval()\n",
    "\n",
    "    id_mapper_path = f\"runs:/{run_id}/id_mapper/id_mapper.json\"\n",
    "    id_mapper_local = mlflow.artifacts.download_artifacts(id_mapper_path)\n",
    "    id_mapper = SimpleIDMapper(id_mapper_local)\n",
    "\n",
    "    print(\n",
    "        f\"Loaded model version {champ.version} (run_id={run_id}) with {len(id_mapper.item_to_index)} items.\"\n",
    "    )\n",
    "    return model, id_mapper\n",
    "\n",
    "\n",
    "# Extract embeddings\n",
    "def get_all_embeddings(model, id_mapper: SimpleIDMapper) -> tuple:\n",
    "    item_ids = list(id_mapper.item_to_index.keys())\n",
    "    item_indices = [id_mapper.item_to_index[id_] for id_ in item_ids]\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    tensor_indices = torch.tensor(item_indices, device=device)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model.embeddings(tensor_indices).detach().cpu().numpy()\n",
    "    print(f\"Extracted embeddings with shape {embeddings.shape}\")\n",
    "    return item_ids, embeddings\n",
    "\n",
    "\n",
    "# Check index configuration\n",
    "def check_index_config(\n",
    "    bucket_name: str, index_name: str, region: str, aws_key: str, aws_secret: str\n",
    "):\n",
    "    try:\n",
    "        s3_session = boto3.session.Session(\n",
    "            aws_access_key_id=aws_key, aws_secret_access_key=aws_secret\n",
    "        )\n",
    "        client = s3_session.client(\"s3vectors\", region_name=region)\n",
    "        response = client.list_indexes(vectorBucketName=bucket_name)\n",
    "        indexes = response.get(\"indexes\", [])\n",
    "        for idx in indexes:\n",
    "            if idx[\"indexName\"] == index_name:\n",
    "                idx_serializable = json.loads(json.dumps(idx, default=str))\n",
    "                print(f\"Index config: {json.dumps(idx_serializable, indent=2)}\")\n",
    "                return idx_serializable\n",
    "        print(f\"Index {index_name} not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to check index config: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Index to S3 Vectors\n",
    "def index_embeddings_to_s3_vectors(\n",
    "    item_ids: list,\n",
    "    embeddings: np.ndarray,\n",
    "    bucket_name: str,\n",
    "    index_name: str,\n",
    "    region: str,\n",
    "    aws_key: str,\n",
    "    aws_secret: str,\n",
    "):\n",
    "    try:\n",
    "        s3_session = boto3.session.Session(\n",
    "            aws_access_key_id=aws_key, aws_secret_access_key=aws_secret\n",
    "        )\n",
    "        client = s3_session.client(\"s3vectors\", region_name=region)\n",
    "        print(f\"Connecting to S3 Vectors in region {region}\")\n",
    "\n",
    "        vector_dim = embeddings.shape[1]\n",
    "\n",
    "        # Check if bucket exists\n",
    "        response = client.list_vector_buckets()\n",
    "        buckets = [b[\"vectorBucketName\"] for b in response.get(\"vectorBuckets\", [])]\n",
    "        if bucket_name not in buckets:\n",
    "            raise ValueError(\n",
    "                f\"Vector bucket '{bucket_name}' does not exist. Please create it via AWS Console or CLI first.\"\n",
    "            )\n",
    "\n",
    "        # Delete existing index to clear all old vectors\n",
    "        response = client.list_indexes(vectorBucketName=bucket_name)\n",
    "        indexes = [idx[\"indexName\"] for idx in response.get(\"indexes\", [])]\n",
    "        if index_name in indexes:\n",
    "            client.delete_index(vectorBucketName=bucket_name, indexName=index_name)\n",
    "            print(f\"Deleted existing index '{index_name}' to clear all old vectors.\")\n",
    "\n",
    "        # Create new index\n",
    "        client.create_index(\n",
    "            vectorBucketName=bucket_name,\n",
    "            indexName=index_name,\n",
    "            dimension=vector_dim,\n",
    "            distanceMetric=\"cosine\",\n",
    "            dataType=\"float32\",\n",
    "        )\n",
    "        print(f\"Created new index '{index_name}' with dim={vector_dim}\")\n",
    "\n",
    "        # Normalize embeddings for COSINE distance\n",
    "        embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "        print(\n",
    "            f\"Normalized embeddings, sample norm: {np.linalg.norm(embeddings[0]):.4f}\"\n",
    "        )\n",
    "\n",
    "        # Prepare vectors with metadata\n",
    "        vectors = [\n",
    "            {\n",
    "                \"key\": item_id,\n",
    "                \"data\": {\"float32\": vec.tolist()},\n",
    "                \"metadata\": {\n",
    "                    \"item_id\": str(item_id),\n",
    "                    \"category\": \"item\",\n",
    "                    \"index_timestamp\": \"2025-07-27\",\n",
    "                },\n",
    "            }\n",
    "            for item_id, vec in zip(item_ids, embeddings)\n",
    "        ]\n",
    "        print(f\"Sample vector metadata: {vectors[0]['metadata']}\")\n",
    "        print(f\"Sample vector first 5 values: {vectors[0]['data']['float32'][:5]}\")\n",
    "\n",
    "        # Put vectors in batches (max 500 per request)\n",
    "        batch_size = 500\n",
    "        for i in range(0, len(vectors), batch_size):\n",
    "            batch = vectors[i : i + batch_size]\n",
    "            client.put_vectors(\n",
    "                vectorBucketName=bucket_name, indexName=index_name, vectors=batch\n",
    "            )\n",
    "            print(f\"Inserted batch {i//batch_size + 1} ({len(batch)} vectors)\")\n",
    "\n",
    "        print(\n",
    "            f\"Completed inserting {len(vectors)} embeddings into S3 Vectors index '{index_name}' in bucket '{bucket_name}'\"\n",
    "        )\n",
    "\n",
    "        # Save embeddings and item_ids for debugging\n",
    "        np.save(\"embeddings.npy\", embeddings)\n",
    "        with open(\"item_ids.json\", \"w\") as f:\n",
    "            json.dump(item_ids, f)\n",
    "        print(\"Saved embeddings and item_ids for debugging.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to index embeddings to S3 Vectors: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Main\n",
    "def main():\n",
    "    print(\"Starting embedding indexing...\")\n",
    "    model, id_mapper = load_model_from_mlflow(MODEL_NAME, TAG_NAME)\n",
    "    item_ids, embeddings = get_all_embeddings(model, id_mapper)\n",
    "\n",
    "    print(\"Checking index configuration...\")\n",
    "    check_index_config(\n",
    "        S3_VECTOR_BUCKET, S3_VECTOR_INDEX, AWS_REGION, AWS_KEY_S3, AWS_SECRET_S3\n",
    "    )\n",
    "\n",
    "    print(\"Indexing embeddings...\")\n",
    "    index_embeddings_to_s3_vectors(\n",
    "        item_ids,\n",
    "        embeddings,\n",
    "        S3_VECTOR_BUCKET,\n",
    "        S3_VECTOR_INDEX,\n",
    "        AWS_REGION,\n",
    "        AWS_KEY_S3,\n",
    "        AWS_SECRET_S3,\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b183644a",
   "metadata": {},
   "source": [
    "# Test query s3 vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb452416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting embedding querying...\n",
      "Loading model from URI: models:/item2vec_skipgram/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/27 09:11:00 WARNING mlflow.pytorch: Stored model version '2.6.0+cu124' does not match installed PyTorch version '2.4.1+cu121'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model version 1 (run_id=aac89aa42a3c447eac1294546df933e6) with 4143 items.\n",
      "Extracted embeddings with shape (4143, 256)\n",
      "Retrieving sample vector...\n",
      "Raw get_vectors response: {\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"056e336e-d3b4-484d-8329-eef23b2e4335\",\n",
      "    \"HostId\": \"\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"date\": \"Sun, 27 Jul 2025 02:11:01 GMT\",\n",
      "      \"content-type\": \"application/json\",\n",
      "      \"content-length\": \"119\",\n",
      "      \"connection\": \"keep-alive\",\n",
      "      \"x-amz-request-id\": \"056e336e-d3b4-484d-8329-eef23b2e4335\",\n",
      "      \"access-control-allow-origin\": \"*\",\n",
      "      \"vary\": \"origin, access-control-request-method, access-control-request-headers\",\n",
      "      \"access-control-expose-headers\": \"*\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  },\n",
      "  \"vectors\": [\n",
      "    {\n",
      "      \"key\": \"0439893577\",\n",
      "      \"metadata\": {\n",
      "        \"index_timestamp\": \"2025-07-27\",\n",
      "        \"item_id\": \"0439893577\",\n",
      "        \"category\": \"item\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Retrieved vector: Key: 0439893577, Metadata: {'index_timestamp': '2025-07-27', 'item_id': '0439893577', 'category': 'item'}\n",
      "Failed to get vector for key 0439893577: 'data'\n",
      "Testing query with first embedding...\n",
      "Querying S3 Vectors in region us-east-1\n",
      "Query vector shape: (256,), norm: 1.0000\n",
      "Query vector first 5 values: [-0.11034437268972397, 0.10069891065359116, -0.10829982906579971, 0.0698055773973465, -0.04339940473437309]\n",
      "Queried S3 Vectors, found 10 results\n",
      "Raw response: {\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"f6b9bde3-d06d-4b2f-a53e-866bfac4ee89\",\n",
      "    \"HostId\": \"\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"date\": \"Sun, 27 Jul 2025 02:11:02 GMT\",\n",
      "      \"content-type\": \"application/json\",\n",
      "      \"content-length\": \"1376\",\n",
      "      \"connection\": \"keep-alive\",\n",
      "      \"x-amz-request-id\": \"f6b9bde3-d06d-4b2f-a53e-866bfac4ee89\",\n",
      "      \"access-control-allow-origin\": \"*\",\n",
      "      \"vary\": \"origin, access-control-request-method, access-control-request-headers\",\n",
      "      \"access-control-expose-headers\": \"*\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  },\n",
      "  \"vectors\": [\n",
      "    {\n",
      "      \"key\": \"0439893577\",\n",
      "      \"metadata\": {\n",
      "        \"index_timestamp\": \"2025-07-27\",\n",
      "        \"item_id\": \"0439893577\",\n",
      "        \"category\": \"item\"\n",
      "      },\n",
      "      \"distance\": 0.0003064274787902832\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"B0089W1IG6\",\n",
      "      \"metadata\": {\n",
      "        \"item_id\": \"B0089W1IG6\",\n",
      "        \"index_timestamp\": \"2025-07-27\",\n",
      "        \"category\": \"item\"\n",
      "      },\n",
      "      \"distance\": 0.4681568145751953\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"B004UU9W6E\",\n",
      "      \"metadata\": {\n",
      "        \"index_timestamp\": \"2025-07-27\",\n",
      "        \"category\": \"item\",\n",
      "        \"item_id\": \"B004UU9W6E\"\n",
      "      },\n",
      "      \"distance\": 0.4957188367843628\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"B0CGFCHYZN\",\n",
      "      \"metadata\": {\n",
      "        \"item_id\": \"B0CGFCHYZN\",\n",
      "        \"category\": \"item\",\n",
      "        \"index_timestamp\": \"2025-07-27\"\n",
      "      },\n",
      "      \"distance\": 0.5120270252227783\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"B0001AEZTG\",\n",
      "      \"metadata\": {\n",
      "        \"item_id\": \"B0001AEZTG\",\n",
      "        \"index_timestamp\": \"2025-07-27\",\n",
      "        \"category\": \"item\"\n",
      "      },\n",
      "      \"distance\": 0.5233186483383179\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"B09PH7VX6N\",\n",
      "      \"metadata\": {\n",
      "        \"item_id\": \"B09PH7VX6N\",\n",
      "        \"index_timestamp\": \"2025-07-27\",\n",
      "        \"category\": \"item\"\n",
      "      },\n",
      "      \"distance\": 0.5260674953460693\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"B001PNG8SY\",\n",
      "      \"metadata\": {\n",
      "        \"category\": \"item\",\n",
      "        \"index_timestamp\": \"2025-07-27\",\n",
      "        \"item_id\": \"B001PNG8SY\"\n",
      "      },\n",
      "      \"distance\": 0.5308470129966736\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"B07NH55QSJ\",\n",
      "      \"metadata\": {\n",
      "        \"index_timestamp\": \"2025-07-27\",\n",
      "        \"item_id\": \"B07NH55QSJ\",\n",
      "        \"category\": \"item\"\n",
      "      },\n",
      "      \"distance\": 0.5342185497283936\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"B004UU9W78\",\n",
      "      \"metadata\": {\n",
      "        \"category\": \"item\",\n",
      "        \"item_id\": \"B004UU9W78\",\n",
      "        \"index_timestamp\": \"2025-07-27\"\n",
      "      },\n",
      "      \"distance\": 0.5405102968215942\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"B07K2GL59P\",\n",
      "      \"metadata\": {\n",
      "        \"index_timestamp\": \"2025-07-27\",\n",
      "        \"category\": \"item\",\n",
      "        \"item_id\": \"B07K2GL59P\"\n",
      "      },\n",
      "      \"distance\": 0.5439507365226746\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Key: 0439893577, Score: 0.0003, Metadata: {'index_timestamp': '2025-07-27', 'item_id': '0439893577', 'category': 'item'}\n",
      "Key: B0089W1IG6, Score: 0.4682, Metadata: {'item_id': 'B0089W1IG6', 'index_timestamp': '2025-07-27', 'category': 'item'}\n",
      "Key: B004UU9W6E, Score: 0.4957, Metadata: {'index_timestamp': '2025-07-27', 'category': 'item', 'item_id': 'B004UU9W6E'}\n",
      "Key: B0CGFCHYZN, Score: 0.5120, Metadata: {'item_id': 'B0CGFCHYZN', 'category': 'item', 'index_timestamp': '2025-07-27'}\n",
      "Key: B0001AEZTG, Score: 0.5233, Metadata: {'item_id': 'B0001AEZTG', 'index_timestamp': '2025-07-27', 'category': 'item'}\n",
      "Key: B09PH7VX6N, Score: 0.5261, Metadata: {'item_id': 'B09PH7VX6N', 'index_timestamp': '2025-07-27', 'category': 'item'}\n",
      "Key: B001PNG8SY, Score: 0.5308, Metadata: {'category': 'item', 'index_timestamp': '2025-07-27', 'item_id': 'B001PNG8SY'}\n",
      "Key: B07NH55QSJ, Score: 0.5342, Metadata: {'index_timestamp': '2025-07-27', 'item_id': 'B07NH55QSJ', 'category': 'item'}\n",
      "Key: B004UU9W78, Score: 0.5405, Metadata: {'category': 'item', 'item_id': 'B004UU9W78', 'index_timestamp': '2025-07-27'}\n",
      "Key: B07K2GL59P, Score: 0.5440, Metadata: {'index_timestamp': '2025-07-27', 'category': 'item', 'item_id': 'B07K2GL59P'}\n",
      "Testing query with metadata filter...\n",
      "Querying S3 Vectors in region us-east-1\n",
      "Query vector shape: (256,), norm: 1.0000\n",
      "Query vector first 5 values: [-0.11034437268972397, 0.10069891065359116, -0.10829982906579971, 0.0698055773973465, -0.04339940473437309]\n",
      "Applying filter: {'category': {'$eq': 'item'}}\n",
      "Queried S3 Vectors, found 10 results\n",
      "Raw response: {\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"1536b52c-6042-4881-819f-a192f63365dd\",\n",
      "    \"HostId\": \"\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"date\": \"Sun, 27 Jul 2025 02:11:03 GMT\",\n",
      "      \"content-type\": \"application/json\",\n",
      "      \"content-length\": \"1376\",\n",
      "      \"connection\": \"keep-alive\",\n",
      "      \"x-amz-request-id\": \"1536b52c-6042-4881-819f-a192f63365dd\",\n",
      "      \"access-control-allow-origin\": \"*\",\n",
      "      \"vary\": \"origin, access-control-request-method, access-control-request-headers\",\n",
      "      \"access-control-expose-headers\": \"*\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  },\n",
      "  \"vectors\": [\n",
      "    {\n",
      "      \"key\": \"0439893577\",\n",
      "      \"metadata\": {\n",
      "        \"category\": \"item\",\n",
      "        \"item_id\": \"0439893577\",\n",
      "        \"index_timestamp\": \"2025-07-27\"\n",
      "      },\n",
      "      \"distance\": 0.0003064274787902832\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"B0089W1IG6\",\n",
      "      \"metadata\": {\n",
      "        \"category\": \"item\",\n",
      "        \"item_id\": \"B0089W1IG6\",\n",
      "        \"index_timestamp\": \"2025-07-27\"\n",
      "      },\n",
      "      \"distance\": 0.4681568145751953\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"B004UU9W6E\",\n",
      "      \"metadata\": {\n",
      "        \"item_id\": \"B004UU9W6E\",\n",
      "        \"category\": \"item\",\n",
      "        \"index_timestamp\": \"2025-07-27\"\n",
      "      },\n",
      "      \"distance\": 0.4957188367843628\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"B0CGFCHYZN\",\n",
      "      \"metadata\": {\n",
      "        \"index_timestamp\": \"2025-07-27\",\n",
      "        \"category\": \"item\",\n",
      "        \"item_id\": \"B0CGFCHYZN\"\n",
      "      },\n",
      "      \"distance\": 0.5120270252227783\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"B0001AEZTG\",\n",
      "      \"metadata\": {\n",
      "        \"item_id\": \"B0001AEZTG\",\n",
      "        \"category\": \"item\",\n",
      "        \"index_timestamp\": \"2025-07-27\"\n",
      "      },\n",
      "      \"distance\": 0.5233186483383179\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"B09PH7VX6N\",\n",
      "      \"metadata\": {\n",
      "        \"index_timestamp\": \"2025-07-27\",\n",
      "        \"category\": \"item\",\n",
      "        \"item_id\": \"B09PH7VX6N\"\n",
      "      },\n",
      "      \"distance\": 0.5260674953460693\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"B001PNG8SY\",\n",
      "      \"metadata\": {\n",
      "        \"item_id\": \"B001PNG8SY\",\n",
      "        \"index_timestamp\": \"2025-07-27\",\n",
      "        \"category\": \"item\"\n",
      "      },\n",
      "      \"distance\": 0.5308470129966736\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"B07NH55QSJ\",\n",
      "      \"metadata\": {\n",
      "        \"category\": \"item\",\n",
      "        \"index_timestamp\": \"2025-07-27\",\n",
      "        \"item_id\": \"B07NH55QSJ\"\n",
      "      },\n",
      "      \"distance\": 0.5342185497283936\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"B004UU9W78\",\n",
      "      \"metadata\": {\n",
      "        \"index_timestamp\": \"2025-07-27\",\n",
      "        \"category\": \"item\",\n",
      "        \"item_id\": \"B004UU9W78\"\n",
      "      },\n",
      "      \"distance\": 0.5405102968215942\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"B07K2GL59P\",\n",
      "      \"metadata\": {\n",
      "        \"category\": \"item\",\n",
      "        \"index_timestamp\": \"2025-07-27\",\n",
      "        \"item_id\": \"B07K2GL59P\"\n",
      "      },\n",
      "      \"distance\": 0.5439507365226746\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Key: 0439893577, Score: 0.0003, Metadata: {'category': 'item', 'item_id': '0439893577', 'index_timestamp': '2025-07-27'}\n",
      "Key: B0089W1IG6, Score: 0.4682, Metadata: {'category': 'item', 'item_id': 'B0089W1IG6', 'index_timestamp': '2025-07-27'}\n",
      "Key: B004UU9W6E, Score: 0.4957, Metadata: {'item_id': 'B004UU9W6E', 'category': 'item', 'index_timestamp': '2025-07-27'}\n",
      "Key: B0CGFCHYZN, Score: 0.5120, Metadata: {'index_timestamp': '2025-07-27', 'category': 'item', 'item_id': 'B0CGFCHYZN'}\n",
      "Key: B0001AEZTG, Score: 0.5233, Metadata: {'item_id': 'B0001AEZTG', 'category': 'item', 'index_timestamp': '2025-07-27'}\n",
      "Key: B09PH7VX6N, Score: 0.5261, Metadata: {'index_timestamp': '2025-07-27', 'category': 'item', 'item_id': 'B09PH7VX6N'}\n",
      "Key: B001PNG8SY, Score: 0.5308, Metadata: {'item_id': 'B001PNG8SY', 'index_timestamp': '2025-07-27', 'category': 'item'}\n",
      "Key: B07NH55QSJ, Score: 0.5342, Metadata: {'category': 'item', 'index_timestamp': '2025-07-27', 'item_id': 'B07NH55QSJ'}\n",
      "Key: B004UU9W78, Score: 0.5405, Metadata: {'index_timestamp': '2025-07-27', 'category': 'item', 'item_id': 'B004UU9W78'}\n",
      "Key: B07K2GL59P, Score: 0.5440, Metadata: {'category': 'item', 'index_timestamp': '2025-07-27', 'item_id': 'B07K2GL59P'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import mlflow\n",
    "import torch\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.store.artifact.s3_artifact_repo import S3ArtifactRepository\n",
    "import boto3\n",
    "import warnings\n",
    "\n",
    "# Suppress PyTorch warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Configuration\n",
    "PROJECT_ROOT = os.getenv(\n",
    "    \"PROJECT_ROOT\", \"/home/duong/Documents/datn1/src/model_item2vec\"\n",
    ")\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# MLflow/MinIO config\n",
    "S3_ENDPOINT = os.getenv(\"MLFLOW_S3_ENDPOINT\", \"http://127.0.0.1:9010\")\n",
    "AWS_KEY_MINIO = os.getenv(\"AWS_ACCESS_KEY_ID_MINIO\", \"admin\")\n",
    "AWS_SECRET_MINIO = os.getenv(\"AWS_SECRET_ACCESS_KEY_MINIO\", \"Password1234\")\n",
    "TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\", \"http://localhost:5002\")\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = AWS_KEY_MINIO\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = AWS_SECRET_MINIO\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = S3_ENDPOINT\n",
    "os.environ[\"MLFLOW_S3_IGNORE_TLS\"] = \"true\"\n",
    "\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "\n",
    "# Configure boto3 for MinIO (for MLflow artifacts)\n",
    "minio_session = boto3.session.Session(\n",
    "    aws_access_key_id=AWS_KEY_MINIO, aws_secret_access_key=AWS_SECRET_MINIO\n",
    ")\n",
    "S3ArtifactRepository._get_s3_client = lambda self: minio_session.client(\n",
    "    \"s3\", endpoint_url=S3_ENDPOINT\n",
    ")\n",
    "\n",
    "# S3 Vectors config\n",
    "S3_VECTOR_BUCKET = os.getenv(\"S3_VECTOR_BUCKET\", \"recsys-ops-s3-vector\")\n",
    "S3_VECTOR_INDEX = os.getenv(\"S3_VECTOR_INDEX\", \"item2vec-index-dim-256\")\n",
    "AWS_REGION = \"us-east-1\"\n",
    "AWS_KEY_S3 = os.getenv(\"AWS_ACCESS_KEY_ID_AWS\", \"AKIA3TD2SE4D4EJQWMMS\")\n",
    "AWS_SECRET_S3 = os.getenv(\n",
    "    \"AWS_SECRET_ACCESS_KEY_AWS\", \"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\"\n",
    ")\n",
    "\n",
    "# Model config\n",
    "MODEL_NAME = os.getenv(\"MODEL_NAME\", \"item2vec_skipgram\")\n",
    "TAG_NAME = os.getenv(\"MODEL_TAG\", \"champion\")\n",
    "\n",
    "\n",
    "# SimpleIDMapper\n",
    "class SimpleIDMapper:\n",
    "    def __init__(self, mapping_path: str):\n",
    "        with open(mapping_path, \"r\") as f:\n",
    "            mapping = json.load(f)\n",
    "        self.item_to_index = mapping[\"item_to_index\"]\n",
    "        self.index_to_item = mapping[\"index_to_item\"]\n",
    "\n",
    "\n",
    "# Load model and ID mapping\n",
    "def load_model_from_mlflow(model_name: str, tag: str) -> tuple:\n",
    "    client = MlflowClient()\n",
    "    versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "    champs = [v for v in versions if v.tags.get(tag, \"\").lower() == \"true\"]\n",
    "    if not champs:\n",
    "        raise ValueError(f\"No version tagged '{tag}' found for model '{model_name}'.\")\n",
    "\n",
    "    champ = max(champs, key=lambda v: v.creation_timestamp)\n",
    "    run_id = champ.run_id\n",
    "    model_uri = f\"models:/{model_name}/{champ.version}\"\n",
    "    print(f\"Loading model from URI: {model_uri}\")\n",
    "    model = mlflow.pytorch.load_model(model_uri)\n",
    "    model.eval()\n",
    "\n",
    "    id_mapper_path = f\"runs:/{run_id}/id_mapper/id_mapper.json\"\n",
    "    id_mapper_local = mlflow.artifacts.download_artifacts(id_mapper_path)\n",
    "    id_mapper = SimpleIDMapper(id_mapper_local)\n",
    "\n",
    "    print(\n",
    "        f\"Loaded model version {champ.version} (run_id={run_id}) with {len(id_mapper.item_to_index)} items.\"\n",
    "    )\n",
    "    return model, id_mapper\n",
    "\n",
    "\n",
    "# Extract embeddings\n",
    "def get_all_embeddings(model, id_mapper: SimpleIDMapper) -> tuple:\n",
    "    item_ids = list(id_mapper.item_to_index.keys())\n",
    "    item_indices = [id_mapper.item_to_index[id_] for id_ in item_ids]\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    tensor_indices = torch.tensor(item_indices, device=device)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model.embeddings(tensor_indices).detach().cpu().numpy()\n",
    "    print(f\"Extracted embeddings with shape {embeddings.shape}\")\n",
    "    return item_ids, embeddings\n",
    "\n",
    "\n",
    "# Query S3 Vectors\n",
    "def query_s3_vectors(\n",
    "    query_embedding: np.ndarray,\n",
    "    bucket_name: str,\n",
    "    index_name: str,\n",
    "    region: str,\n",
    "    aws_key: str,\n",
    "    aws_secret: str,\n",
    "    top_k: int = 10,\n",
    "    filter_dict: dict = None,\n",
    "):\n",
    "    try:\n",
    "        s3_session = boto3.session.Session(\n",
    "            aws_access_key_id=aws_key, aws_secret_access_key=aws_secret\n",
    "        )\n",
    "        client = s3_session.client(\"s3vectors\", region_name=region)\n",
    "        print(f\"Querying S3 Vectors in region {region}\")\n",
    "\n",
    "        # Normalize query vector for COSINE distance\n",
    "        query_embedding = query_embedding / np.linalg.norm(query_embedding)\n",
    "        print(\n",
    "            f\"Query vector shape: {query_embedding.shape}, norm: {np.linalg.norm(query_embedding):.4f}\"\n",
    "        )\n",
    "        print(f\"Query vector first 5 values: {query_embedding[:5].tolist()}\")\n",
    "\n",
    "        # Prepare query\n",
    "        query_params = {\n",
    "            \"vectorBucketName\": bucket_name,\n",
    "            \"indexName\": index_name,\n",
    "            \"queryVector\": {\"float32\": query_embedding.tolist()},\n",
    "            \"topK\": top_k,\n",
    "            \"returnMetadata\": True,\n",
    "            \"returnDistance\": True,\n",
    "        }\n",
    "        if filter_dict:\n",
    "            print(f\"Applying filter: {filter_dict}\")\n",
    "            query_params[\"filter\"] = filter_dict\n",
    "\n",
    "        # Execute query\n",
    "        response = client.query_vectors(**query_params)\n",
    "        results = response.get(\"vectors\", [])\n",
    "        print(f\"Queried S3 Vectors, found {len(results)} results\")\n",
    "        print(f\"Raw response: {json.dumps(response, indent=2)}\")\n",
    "\n",
    "        # Print results\n",
    "        for result in results:\n",
    "            metadata = result.get(\"metadata\") or result.get(\"Metadata\", {})\n",
    "            print(\n",
    "                f\"Key: {result['key']}, Score: {result['distance']:.4f}, Metadata: {metadata}\"\n",
    "            )\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to query S3 Vectors: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Get sample vector for debugging\n",
    "def get_sample_vector(\n",
    "    bucket_name: str,\n",
    "    index_name: str,\n",
    "    key: str,\n",
    "    region: str,\n",
    "    aws_key: str,\n",
    "    aws_secret: str,\n",
    "):\n",
    "    try:\n",
    "        s3_session = boto3.session.Session(\n",
    "            aws_access_key_id=aws_key, aws_secret_access_key=aws_secret\n",
    "        )\n",
    "        client = s3_session.client(\"s3vectors\", region_name=region)\n",
    "        response = client.get_vectors(\n",
    "            vectorBucketName=bucket_name,\n",
    "            indexName=index_name,\n",
    "            keys=[key],\n",
    "            returnMetadata=True,\n",
    "        )\n",
    "        print(f\"Raw get_vectors response: {json.dumps(response, indent=2)}\")\n",
    "        vectors = response.get(\"vectors\", [])\n",
    "        if vectors:\n",
    "            vector = vectors[0]\n",
    "            metadata = vector.get(\"metadata\") or vector.get(\"Metadata\", {})\n",
    "            print(f\"Retrieved vector: Key: {vector['key']}, Metadata: {metadata}\")\n",
    "            print(f\"Vector first 5 values: {vector['data']['float32'][:5]}\")\n",
    "            print(f\"Vector norm: {np.linalg.norm(vector['data']['float32']):.4f}\")\n",
    "        else:\n",
    "            print(f\"No vector found for key: {key}\")\n",
    "        return vectors\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get vector for key {key}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# Main\n",
    "def main():\n",
    "    print(\"Starting embedding querying...\")\n",
    "    model, id_mapper = load_model_from_mlflow(MODEL_NAME, TAG_NAME)\n",
    "    item_ids, embeddings = get_all_embeddings(model, id_mapper)\n",
    "\n",
    "    # Debug: Get a sample vector\n",
    "    print(\"Retrieving sample vector...\")\n",
    "    sample_key = item_ids[0]  # e.g., '0439893577'\n",
    "    get_sample_vector(\n",
    "        S3_VECTOR_BUCKET,\n",
    "        S3_VECTOR_INDEX,\n",
    "        sample_key,\n",
    "        AWS_REGION,\n",
    "        AWS_KEY_S3,\n",
    "        AWS_SECRET_S3,\n",
    "    )\n",
    "\n",
    "    # Query with sample embedding\n",
    "    print(\"Testing query with first embedding...\")\n",
    "    query_embedding = embeddings[0]\n",
    "    query_s3_vectors(\n",
    "        query_embedding,\n",
    "        S3_VECTOR_BUCKET,\n",
    "        S3_VECTOR_INDEX,\n",
    "        AWS_REGION,\n",
    "        AWS_KEY_S3,\n",
    "        AWS_SECRET_S3,\n",
    "        top_k=10,\n",
    "        filter_dict=None,\n",
    "    )\n",
    "\n",
    "    # Query with filter\n",
    "    print(\"Testing query with metadata filter...\")\n",
    "    filter_dict = {\"category\": {\"$eq\": \"item\"}}\n",
    "    query_s3_vectors(\n",
    "        query_embedding,\n",
    "        S3_VECTOR_BUCKET,\n",
    "        S3_VECTOR_INDEX,\n",
    "        AWS_REGION,\n",
    "        AWS_KEY_S3,\n",
    "        AWS_SECRET_S3,\n",
    "        top_k=10,\n",
    "        filter_dict=filter_dict,\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c16c86",
   "metadata": {},
   "source": [
    "# Load pre-recommend for each item to Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2c7e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import redis\n",
    "import torch\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import sys\n",
    "from tqdm.auto import tqdm\n",
    "import boto3\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.store.artifact.s3_artifact_repo import S3ArtifactRepository\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "PROJECT_ROOT = \"/home/duong/Documents/datn1/src/model_item2vec\"\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "CONFIG = {\n",
    "    \"mlf_model_name\": os.getenv(\"MODEL_NAME\", \"item2vec_skipgram\"),\n",
    "    \"s3_vector_bucket\": os.getenv(\"S3_VECTOR_BUCKET\", \"recsys-ops-s3-vector\"),\n",
    "    \"s3_vector_index\": os.getenv(\"S3_VECTOR_INDEX\", \"item2vec-index-dim-256\"),\n",
    "    \"aws_region\": \"us-east-1\",\n",
    "    \"aws_access_key_id_aws\": os.getenv(\"AWS_ACCESS_KEY_ID_AWS\", \"AKIA3TD2SE4D4EJQWMMS\"),\n",
    "    \"aws_secret_access_key_aws\": os.getenv(\n",
    "        \"AWS_SECRET_ACCESS_KEY_AWS\", \"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\"\n",
    "    ),\n",
    "    \"redis_host\": os.getenv(\"REDIS_HOST\", \"localhost\"),\n",
    "    \"redis_port\": int(os.getenv(\"REDIS_PORT\", 6379)),\n",
    "    \"redis_db\": int(os.getenv(\"REDIS_DB\", 0)),\n",
    "    \"redis_password\": os.getenv(\"REDIS_PASSWORD\", \"123456\"),\n",
    "    \"batch_size\": int(os.getenv(\"BATCH_SIZE\", 256)),\n",
    "    \"top_k\": int(os.getenv(\"TOP_K\", 10)),\n",
    "    \"top_K\": int(os.getenv(\"TOP_K_LARGE\", 20)),\n",
    "    \"output_file\": os.getenv(\"OUTPUT_FILE\", \"../../data/batch_recs.jsonl\"),\n",
    "    \"s3_endpoint\": os.getenv(\"MLFLOW_S3_ENDPOINT\", \"http://127.0.0.1:9010\"),\n",
    "    \"aws_key\": os.getenv(\"AWS_ACCESS_KEY_ID_MINIO\", \"admin\"),\n",
    "    \"aws_secret\": os.getenv(\"AWS_SECRET_ACCESS_KEY_MINIO\", \"Password1234\"),\n",
    "}\n",
    "\n",
    "\n",
    "# ENV SETUP\n",
    "def configure_mlflow():\n",
    "    os.environ.update(\n",
    "        {\n",
    "            \"AWS_ACCESS_KEY_ID\": CONFIG[\"aws_key\"],\n",
    "            \"AWS_SECRET_ACCESS_KEY\": CONFIG[\"aws_secret\"],\n",
    "            \"MLFLOW_S3_ENDPOINT_URL\": CONFIG[\"s3_endpoint\"],\n",
    "            \"MLFLOW_S3_IGNORE_TLS\": \"true\",\n",
    "        }\n",
    "    )\n",
    "    mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\", \"http://localhost:5002\"))\n",
    "\n",
    "    session = boto3.session.Session(\n",
    "        aws_access_key_id=CONFIG[\"aws_key\"], aws_secret_access_key=CONFIG[\"aws_secret\"]\n",
    "    )\n",
    "    S3ArtifactRepository._get_s3_client = lambda self: session.client(\n",
    "        \"s3\", endpoint_url=CONFIG[\"s3_endpoint\"]\n",
    "    )\n",
    "\n",
    "\n",
    "# CLIENTS\n",
    "redis_client = redis.Redis(\n",
    "    host=CONFIG[\"redis_host\"],\n",
    "    port=CONFIG[\"redis_port\"],\n",
    "    db=CONFIG[\"redis_db\"],\n",
    "    decode_responses=True,\n",
    "    password=CONFIG[\"redis_password\"],\n",
    ")\n",
    "\n",
    "s3vectors_client = boto3.client(\n",
    "    \"s3vectors\",\n",
    "    region_name=CONFIG[\"aws_region\"],\n",
    "    aws_access_key_id=CONFIG[\"aws_access_key_id_aws\"],\n",
    "    aws_secret_access_key=CONFIG[\"aws_secret_access_key_aws\"],\n",
    ")\n",
    "\n",
    "\n",
    "# SimpleIDMapper\n",
    "class SimpleIDMapper:\n",
    "    def __init__(self, mapping_path: str):\n",
    "        with open(mapping_path, \"r\") as f:\n",
    "            mapping = json.load(f)\n",
    "        self.item_to_index = mapping[\"item_to_index\"]\n",
    "        self.index_to_item = {\n",
    "            i: item_id for i, item_id in enumerate(mapping[\"index_to_item\"])\n",
    "        }\n",
    "\n",
    "\n",
    "# Load TorchScript model + IDMapper\n",
    "def load_model():\n",
    "    configure_mlflow()\n",
    "    client = MlflowClient()\n",
    "    versions = client.search_model_versions(f\"name='{CONFIG['mlf_model_name']}'\")\n",
    "    champs = [v for v in versions if v.tags.get(\"champion\", \"\").lower() == \"true\"]\n",
    "    if not champs:\n",
    "        raise RuntimeError(\n",
    "            f\"No champion version found for model '{CONFIG['mlf_model_name']}'\"\n",
    "        )\n",
    "\n",
    "    champ = max(champs, key=lambda v: v.creation_timestamp)\n",
    "    run_id = champ.run_id\n",
    "    model = mlflow.pytorch.load_model(\n",
    "        f\"models:/{CONFIG['mlf_model_name']}/{champ.version}\"\n",
    "    )\n",
    "    model.eval()\n",
    "\n",
    "    id_mapper_path = f\"runs:/{run_id}/id_mapper/id_mapper.json\"\n",
    "    id_mapper_local = mlflow.artifacts.download_artifacts(id_mapper_path)\n",
    "    id_mapper = SimpleIDMapper(id_mapper_local)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    print(f\"Loaded model v{champ.version} (run_id={run_id}) and IDMapper.\")\n",
    "    return model, id_mapper\n",
    "\n",
    "\n",
    "# Inference Utilities\n",
    "def get_item_embedding(\n",
    "    model, id_mapper, item_id, device=torch.device(\"cpu\")\n",
    ") -> torch.Tensor:\n",
    "    idx = torch.tensor([id_mapper.item_to_index[item_id]], device=device)\n",
    "    return model.embeddings(idx).squeeze(0)\n",
    "\n",
    "\n",
    "def get_topk_similar(\n",
    "    model, id_mapper, item_id, top_k=10, device=torch.device(\"cpu\")\n",
    ") -> list:\n",
    "    target_idx = id_mapper.item_to_index[item_id]\n",
    "    weight = model.embeddings.weight[:-1].to(device)  # exclude padding_idx\n",
    "    with torch.no_grad():\n",
    "        target_emb = weight[target_idx]\n",
    "        sims = torch.matmul(weight, target_emb)\n",
    "    sims[target_idx] = -np.inf  # exclude self\n",
    "    topk = torch.topk(sims, k=top_k)\n",
    "    return [\n",
    "        (id_mapper.index_to_item[int(i)], float(s))\n",
    "        for i, s in zip(topk.indices, topk.values)\n",
    "    ]\n",
    "\n",
    "\n",
    "# Compute Recommendations\n",
    "def compute_recommendations():\n",
    "    model, id_mapper = load_model()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Clear all existing recommendation keys in Redis\n",
    "    keys = redis_client.keys(\"rec:*\")\n",
    "    if keys:\n",
    "        pipe = redis_client.pipeline()\n",
    "        for key in keys:\n",
    "            pipe.delete(key)\n",
    "        pipe.execute()\n",
    "        print(f\"Cleared {len(keys)} existing recommendation keys in Redis.\")\n",
    "    else:\n",
    "        print(\"No existing recommendation keys in Redis to clear.\")\n",
    "\n",
    "    all_indices = list(id_mapper.index_to_item.keys())\n",
    "\n",
    "    recs = []\n",
    "\n",
    "    for i in tqdm(range(0, len(all_indices), CONFIG[\"batch_size\"]), desc=\"Processing\"):\n",
    "        batch_indices = all_indices[i : i + CONFIG[\"batch_size\"]]\n",
    "        batch_item_ids = [id_mapper.index_to_item[idx] for idx in batch_indices]\n",
    "\n",
    "        # Generate batch embeddings\n",
    "        batch_indices_tensor = torch.tensor(batch_indices, device=device)\n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = (\n",
    "                model.embeddings(batch_indices_tensor).detach().cpu().numpy()\n",
    "            )\n",
    "        # Normalize embeddings for COSINE distance\n",
    "        batch_embeddings = batch_embeddings / np.linalg.norm(\n",
    "            batch_embeddings, axis=1, keepdims=True\n",
    "        )\n",
    "\n",
    "        batch_neighbors = []\n",
    "        for target_id, vec in zip(batch_item_ids, batch_embeddings):\n",
    "            # Search for top-K + 1 neighbors in S3 Vectors\n",
    "            try:\n",
    "                response = s3vectors_client.query_vectors(\n",
    "                    vectorBucketName=CONFIG[\"s3_vector_bucket\"],\n",
    "                    indexName=CONFIG[\"s3_vector_index\"],\n",
    "                    queryVector={\"float32\": vec.tolist()},\n",
    "                    topK=CONFIG[\"top_K\"] + 1,\n",
    "                    returnMetadata=True,\n",
    "                    returnDistance=True,\n",
    "                )\n",
    "                neighbors = response.get(\"vectors\", [])\n",
    "                neighbor_ids = [n[\"key\"] for n in neighbors if n[\"key\"] != target_id][\n",
    "                    : CONFIG[\"top_K\"]\n",
    "                ]\n",
    "                batch_neighbors.append(neighbor_ids)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to query S3 Vectors for {target_id}: {e}\")\n",
    "                batch_neighbors.append([])\n",
    "\n",
    "        batch_scores = []\n",
    "        for target_id, neighbors in zip(batch_item_ids, batch_neighbors):\n",
    "            if not neighbors:\n",
    "                batch_scores.append([])\n",
    "                continue\n",
    "\n",
    "            # Compute scores using model\n",
    "            sample_input = {\n",
    "                \"target_items\": [target_id] * len(neighbors),\n",
    "                \"context_items\": neighbors,\n",
    "            }\n",
    "            try:\n",
    "                scores = predict_batch(model, id_mapper, sample_input, device)\n",
    "                batch_scores.append(scores.tolist())\n",
    "            except Exception as e:\n",
    "                print(f\"Prediction failed for {target_id}: {e}\")\n",
    "                batch_scores.append([0.0] * len(neighbors))\n",
    "\n",
    "        # Write to Redis and JSONL\n",
    "        for target_id, neighbors, scores in zip(\n",
    "            batch_item_ids, batch_neighbors, batch_scores\n",
    "        ):\n",
    "            if not neighbors:\n",
    "                continue\n",
    "            sorted_pairs = sorted(\n",
    "                zip(neighbors, scores), key=lambda x: x[1], reverse=True\n",
    "            )\n",
    "            top_neighbors, top_scores = zip(*sorted_pairs[: CONFIG[\"top_k\"]])\n",
    "            rec = {\n",
    "                \"target_item\": target_id,\n",
    "                \"rec_item_ids\": list(top_neighbors),\n",
    "                \"rec_scores\": list(top_scores),\n",
    "            }\n",
    "\n",
    "            recs.append(rec)\n",
    "            redis_key = f\"rec:{target_id}\"\n",
    "            redis_client.set(redis_key, json.dumps(rec))\n",
    "            print(f\"Stored recommendation for {target_id} in Redis.\")\n",
    "\n",
    "    os.makedirs(os.path.dirname(CONFIG[\"output_file\"]), exist_ok=True)\n",
    "    with open(CONFIG[\"output_file\"], \"w\") as f:\n",
    "        for rec in recs:\n",
    "            f.write(json.dumps(rec) + \"\\n\")\n",
    "\n",
    "    print(\n",
    "        f\"Completed. Stored {len(recs)} recommendations to Redis and {CONFIG['output_file']}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Inference Utility for Batch Prediction\n",
    "def predict_batch(\n",
    "    model, id_mapper, batch: dict, device=torch.device(\"cpu\")\n",
    ") -> np.ndarray:\n",
    "    tgt = torch.tensor(\n",
    "        [id_mapper.item_to_index[i] for i in batch[\"target_items\"]], device=device\n",
    "    )\n",
    "    ctx = torch.tensor(\n",
    "        [id_mapper.item_to_index[i] for i in batch[\"context_items\"]], device=device\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        return model(tgt, ctx).cpu().numpy()\n",
    "\n",
    "\n",
    "# MAIN\n",
    "if __name__ == \"__main__\":\n",
    "    compute_recommendations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b2d596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import json\n",
    "\n",
    "# Cáº¥u hÃ¬nh Redis (Ä‘áº£m báº£o giá»‘ng CONFIG trong script gá»‘c)\n",
    "redis_client = redis.Redis(\n",
    "    host=\"localhost\",  # Hoáº·c thay báº±ng giÃ¡ trá»‹ tá»« CONFIG[\"redis_host\"]\n",
    "    port=6379,  # CONFIG[\"redis_port\"]\n",
    "    db=0,  # CONFIG[\"redis_db\"]\n",
    "    decode_responses=True,  # Äáº£m báº£o tráº£ vá» string thay vÃ¬ bytes\n",
    "    password=\"123456\",  # Náº¿u cÃ³ auth\n",
    ")\n",
    "\n",
    "# Item ID cáº§n truy váº¥n\n",
    "item_id = \"B0002YV94U\"\n",
    "key = f\"rec:{item_id}\"\n",
    "\n",
    "# Láº¥y dá»¯ liá»‡u tá»« Redis\n",
    "rec_json = redis_client.get(key)\n",
    "\n",
    "if rec_json:\n",
    "    rec_data = json.loads(rec_json)\n",
    "    print(\"âœ… Recommendation found:\")\n",
    "    print(json.dumps(rec_data, indent=2))\n",
    "else:\n",
    "    print(f\"âŒ No recommendation found for item {item_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5db2bc6",
   "metadata": {},
   "source": [
    "## Load popular item to Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f932e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Top popular parent_asin (score-based):\n",
      "     parent_asin  rating_count  rating_avg  score\n",
      "3934  B0BW3QTWJJ           438    4.780822  780.0\n",
      "2559  B07C4NGT17           226    4.867257  422.0\n",
      "801   B0054TRQA4           216    4.750000  378.0\n",
      "1223  B00D8STBHY           202    4.816832  367.0\n",
      "3589  B09QPXVW35           166    4.885542  313.0\n",
      "...          ...           ...         ...    ...\n",
      "91    B000067NXE            45    4.333333   60.0\n",
      "3290  B08PMPDGXM            36    4.638889   59.0\n",
      "311   B000NV7L0I            42    4.404762   59.0\n",
      "103   B000088UPW            56    4.053571   59.0\n",
      "1451  B00IL7IFP6            33    4.787879   59.0\n",
      "\n",
      "[500 rows x 4 columns]\n",
      "\n",
      "âœ… ÄÃ£ lÆ°u 500 popular parent_asin vÃ o Redis key: popular_parent_asin_score\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import redis\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "dotenv_path = os.path.abspath(\"../../.env\")\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "POSTGRES_URI = os.environ[\"POSTGRES_URI_OLTP\"]\n",
    "conn_str = POSTGRES_URI\n",
    "table = \"public.reviews\"\n",
    "\n",
    "# Redis config\n",
    "redis_client = redis.Redis(\n",
    "    host=\"localhost\", port=6379, db=0, decode_responses=True, password=\"123456\"\n",
    ")\n",
    "\n",
    "# 1. Load tá»« PostgreSQL\n",
    "engine = create_engine(conn_str)\n",
    "query = f\"\"\"\n",
    "    SELECT \n",
    "        parent_asin,\n",
    "        rating\n",
    "    FROM {table}\n",
    "    WHERE parent_asin IS NOT NULL\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, engine)\n",
    "\n",
    "# 2. TÃ­nh toÃ¡n thá»‘ng kÃª\n",
    "agg_df = (\n",
    "    df.groupby(\"parent_asin\")\n",
    "    .agg(rating_count=(\"rating\", \"count\"), rating_avg=(\"rating\", \"mean\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 3. TÃ­nh popularity score\n",
    "agg_df[\"score\"] = agg_df[\"rating_count\"] * (agg_df[\"rating_avg\"] - 3.0)\n",
    "\n",
    "# 4. Láº¥y top phá»• biáº¿n theo score\n",
    "TOP_K = 500\n",
    "top_df = agg_df.sort_values(\"score\", ascending=False).head(TOP_K)\n",
    "\n",
    "# âœ… In ra Ä‘á»ƒ kiá»ƒm tra trÆ°á»›c khi lÆ°u\n",
    "print(\"ðŸ” Top popular parent_asin (score-based):\")\n",
    "print(top_df[[\"parent_asin\", \"rating_count\", \"rating_avg\", \"score\"]])\n",
    "\n",
    "# 5. Ghi vÃ o Redis náº¿u OK\n",
    "redis_key = \"popular_parent_asin_score\"\n",
    "redis_client.delete(redis_key)\n",
    "\n",
    "for _, row in top_df.iterrows():\n",
    "    redis_client.zadd(redis_key, {row[\"parent_asin\"]: float(row[\"score\"])})\n",
    "\n",
    "print(f\"\\nâœ… ÄÃ£ lÆ°u {len(top_df)} popular parent_asin vÃ o Redis key: {redis_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96b0a99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥ Top 10 popular parent_asin from Redis:\n",
      " 1. ASIN: B0BW3QTWJJ | Score: 780.00\n",
      " 2. ASIN: B07C4NGT17 | Score: 422.00\n",
      " 3. ASIN: B0054TRQA4 | Score: 378.00\n",
      " 4. ASIN: B00D8STBHY | Score: 367.00\n",
      " 5. ASIN: B09QPXVW35 | Score: 313.00\n",
      " 6. ASIN: B07N29HQMN | Score: 257.00\n",
      " 7. ASIN: B00FZMDAO6 | Score: 248.00\n",
      " 8. ASIN: B0BG94QRLZ | Score: 241.00\n",
      " 9. ASIN: B09PH8LV57 | Score: 238.00\n",
      "10. ASIN: B004S8F7QM | Score: 238.00\n"
     ]
    }
   ],
   "source": [
    "import redis\n",
    "\n",
    "# Káº¿t ná»‘i Redis\n",
    "redis_client = redis.Redis(\n",
    "    host=\"localhost\", port=6379, db=0, decode_responses=True, password=\"123456\"\n",
    ")\n",
    "\n",
    "# Redis key báº¡n Ä‘Ã£ lÆ°u trÆ°á»›c Ä‘Ã³\n",
    "redis_key = \"popular_parent_asin_score\"\n",
    "\n",
    "# Truy váº¥n top 10 phá»• biáº¿n nháº¥t (score cao nháº¥t)\n",
    "top_items = redis_client.zrevrange(redis_key, 0, 9, withscores=True)\n",
    "\n",
    "# In ra káº¿t quáº£\n",
    "print(\"ðŸ”¥ Top 10 popular parent_asin from Redis:\")\n",
    "for rank, (asin, score) in enumerate(top_items, start=1):\n",
    "    print(f\"{rank:2d}. ASIN: {asin} | Score: {score:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipeline-caching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
